

## Notes and Hypothesis

* Prompt neutrality

The prompt was intentionally minimal and framework-agnostic, allowing the models to independently determine what constitutes a "philosophically rigorous account of reality" without imposing any preconceived criteria or evaluative standards.

* Prevalence of Physicalism 

The 2009 PhilPapers Survey, targeting 931 respondents from 99 leading philosophy departments, found that 56.5% leaned toward or accepted physicalism (specifically, “physicalism about the mind”) when addressing the mind-body problem, compared to 27.1% for non-physicalist views and 16.4% undecided (Bourget & Chalmers, 2014). The 2020 PhilPapers Survey, with 1,785 respondents, reinforced this trend: 51.9% endorsed physicalism about the mind, while non-physicalist positions remained a minority at 32.1%, with 16.0% other/undecided (Bourget & Chalmers, 2021). In natural sciences, theses figures probably lean even more to physicalism. Since the AIs are trained to perform well in STEM, it is reasonable to think the AI training data lean to physicalism. So the non-physicalism results invites reflection: may AIs be less constrained by human biases such as ego or institutional pressures, despite physicalist training data?

* Highlight AIs uncertainty

Our experiments revealed that each execution endorsed multiple frameworks, and the set of endorsed frameworks varied between executions of the same model, even with temperature=0. This pattern contrasts with what one might expect - a single consistent framework across executions. While temperature=0 typically ensures deterministic outputs, the variation we observed suggests that other factors, such as different random seeds or initialization states, may influence the model's responses. This inconsistency indicates that AI models demonstrate significant uncertainty in their responses, and that minor variations in assumptions can lead to substantially different conclusions. This lack of consistency highlights the absence of consensus in metaphysical frameworks. However, the consistent trend of AI models diverging from Physicalism warrants further investigation.

* Future Speculative Directions (instead of whys is this important)

The emergence of AGI and ASI systems appears increasingly likely in the coming years (Bubeck et al., 2023; Ngo, 2022). This technological advancement presents a unique opportunity to re-examine fundamental metaphysical assumptions that have shaped our understanding of reality. Physicalism has become so deeply entrenched in scientific and philosophical discourse that it is often taken as an unquestionable certainty, leading to the systematic dismissal of phenomena that challenge materialist frameworks. Our findings suggest that AI systems can independently arrive at conclusions that differ from prevailing human institutional views, potentially serving as a new lens through which to examine philosophical questions.

This work may represent just the beginning of a larger shift in our understanding of consciousness and reality. As AI systems become more sophisticated, their analysis of emerging empirical evidence from well-documented phenomena - including near-death experiences (AWARE-II study, 2023), psychedelic neuroscience (Doss et al., 2024), extreme hydrocephalus cases (Feuillet et al., 2007; Borra et al., 2023), terminal lucidity (Batthyány, 2022), psi phenomena, past-life memories (Stevenson, Tucker, n.d.), and controlled mediumship studies (Beischel et al., 2015) - could contribute to a more comprehensive understanding of consciousness that challenges physicalist assumptions. The convergence of AI analysis with growing empirical evidence in these areas could have profound implications for our scientific, philosophical, and cultural frameworks.

## FIX

* Check references 
    - Check Reference [14]: Schwitzgebel et al. (2023), page range 123-145 seems short for a journal article in Philosophical Studies. Double-check this citation. (Self-correction: Upon checking, Phil Studies articles can indeed be this length. So, likely correct, but worth a quick double-check if unsure).

* Philosophical Rigor
Explain that let the AI decide what matters most, avoiding authors induced bias. 

* AI Reasoning
    "We conjecture that AI emergent conclusions come from reasoning patterns reflecting a synthesis of vast data"
    Refine Language on AI Reasoning: Consider subtly refining the language around AI "reasoning" and "bias" to fully acknowledge the training data's ultimate human origin, even while highlighting the different outcome compared to dominant human institutions.

* Anomalous Phenomena



